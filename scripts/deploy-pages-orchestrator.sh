#!/bin/bash
# Deployment Orchestrator for Cloudflare Pages
# ONE WINDOW â€” COPILOT AGENT EXECUTION PLAN
#
# This script:
# 1. Validates required secrets exist (CF_API_TOKEN, CF_ACCOUNT_ID)
# 2. Triggers staging and production deployments in parallel
# 3. Monitors both workflow runs to completion
# 4. Extracts Cloudflare Pages URLs
# 5. Runs smoke checks (HTTP 200 verification)
# 6. Posts final report

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPO="wdhunter645/next-starter-template"
WORKFLOW_FILE="pages-deploy.yml"
STAGING_PROJECT="lgfc-staging"
PRODUCTION_PROJECT="lgfc-prod"
BRANCH="main"

# Result tracking
STAGING_RUN_ID=""
PRODUCTION_RUN_ID=""
STAGING_RUN_URL=""
PRODUCTION_RUN_URL=""
STAGING_URL=""
PRODUCTION_URL=""
STAGING_SUCCESS=false
PRODUCTION_SUCCESS=false

echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}ðŸš€ Cloudflare Pages Deployment Orchestrator${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# PRECHECK: Validate required secrets
echo -e "${YELLOW}PRECHECK: Validating required secrets...${NC}"
echo ""

# Check if gh CLI is authenticated
if ! gh auth status &>/dev/null; then
    echo -e "${RED}âœ— Error: GitHub CLI (gh) is not authenticated${NC}"
    echo "Please run: gh auth login"
    exit 1
fi

echo -e "${GREEN}âœ“ GitHub CLI authenticated${NC}"

# Check required secrets
REQUIRED_SECRETS=("CF_API_TOKEN" "CF_ACCOUNT_ID")
MISSING_SECRETS=()

for secret in "${REQUIRED_SECRETS[@]}"; do
    if gh secret list -R "$REPO" 2>/dev/null | grep -q "^$secret"; then
        echo -e "${GREEN}âœ“ Secret found: $secret${NC}"
    else
        echo -e "${RED}âœ— Secret missing: $secret${NC}"
        MISSING_SECRETS+=("$secret")
    fi
done

if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
    echo ""
    echo -e "${RED}âœ— FAIL FAST: Missing required secrets: ${MISSING_SECRETS[*]}${NC}"
    echo "Please add these secrets to the repository at:"
    echo "https://github.com/$REPO/settings/secrets/actions"
    exit 1
fi

echo ""
echo -e "${GREEN}âœ“ All required secrets are configured${NC}"
echo ""

# STEP 1: Trigger deployments in parallel
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}STEP 1: Triggering deployments in parallel${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Trigger staging deployment
echo -e "${YELLOW}Triggering STAGING deployment...${NC}"
gh workflow run "$WORKFLOW_FILE" \
    -R "$REPO" \
    --ref "$BRANCH" \
    -f environment="staging" \
    -f branch="$BRANCH"

echo -e "${GREEN}âœ“ Staging deployment triggered${NC}"
echo ""

# Wait 20 seconds before triggering production
echo "Waiting 20 seconds before triggering production..."
sleep 20

# Trigger production deployment
echo -e "${YELLOW}Triggering PRODUCTION deployment...${NC}"
gh workflow run "$WORKFLOW_FILE" \
    -R "$REPO" \
    --ref "$BRANCH" \
    -f environment="production" \
    -f branch="$BRANCH"

echo -e "${GREEN}âœ“ Production deployment triggered${NC}"
echo ""

# Wait a moment for runs to be created
echo "Waiting for workflow runs to be created..."
sleep 10

# Get the run IDs
echo "Fetching workflow run IDs..."

# Get staging run (most recent run for pages-deploy.yml)
RUNS_JSON=$(gh run list \
    -R "$REPO" \
    --workflow="$WORKFLOW_FILE" \
    --limit 2 \
    --json databaseId,createdAt,status \
    --jq 'sort_by(.createdAt) | reverse')

# Parse the two most recent runs
STAGING_RUN_ID=$(echo "$RUNS_JSON" | jq -r '.[0].databaseId')
PRODUCTION_RUN_ID=$(echo "$RUNS_JSON" | jq -r '.[1].databaseId')

if [ -z "$STAGING_RUN_ID" ] || [ "$STAGING_RUN_ID" = "null" ]; then
    echo -e "${RED}âœ— Error: Could not find staging workflow run${NC}"
    exit 1
fi

if [ -z "$PRODUCTION_RUN_ID" ] || [ "$PRODUCTION_RUN_ID" = "null" ]; then
    echo -e "${RED}âœ— Error: Could not find production workflow run${NC}"
    exit 1
fi

STAGING_RUN_URL="https://github.com/$REPO/actions/runs/$STAGING_RUN_ID"
PRODUCTION_RUN_URL="https://github.com/$REPO/actions/runs/$PRODUCTION_RUN_ID"

echo -e "${GREEN}âœ“ Staging Run ID: $STAGING_RUN_ID${NC}"
echo "  URL: $STAGING_RUN_URL"
echo -e "${GREEN}âœ“ Production Run ID: $PRODUCTION_RUN_ID${NC}"
echo "  URL: $PRODUCTION_RUN_URL"
echo ""

# STEP 2: Watch both runs to completion
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}STEP 2: Monitoring workflow runs${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Function to monitor a workflow run
monitor_workflow() {
    local run_id=$1
    local environment_name=$2
    
    local max_wait=1800  # 30 minutes
    local elapsed=0
    local check_interval=15
    
    while [ $elapsed -lt $max_wait ]; do
        local run_info=$(gh run view "$run_id" -R "$REPO" --json status,conclusion)
        local status=$(echo "$run_info" | jq -r '.status')
        local conclusion=$(echo "$run_info" | jq -r '.conclusion')
        
        echo -n "[$environment_name] Status: $status"
        
        if [ "$status" = "completed" ]; then
            echo " | Conclusion: $conclusion"
            
            if [ "$conclusion" != "success" ]; then
                echo -e "${RED}âœ— Error: $environment_name workflow failed${NC}"
                echo ""
                echo "Fetching first failing log line..."
                
                # Get logs and extract first error
                local error_log=$(gh run view "$run_id" -R "$REPO" --log-failed 2>&1 | head -20)
                echo "$error_log"
                
                return 1
            fi
            
            echo -e "${GREEN}âœ“ $environment_name deployment completed successfully${NC}"
            return 0
        fi
        
        echo " | Elapsed: ${elapsed}s"
        sleep $check_interval
        elapsed=$((elapsed + check_interval))
    done
    
    echo -e "${RED}âœ— Error: $environment_name workflow timed out${NC}"
    return 1
}

# Monitor both runs in parallel by checking alternately
echo "Monitoring both deployments..."
echo ""

STAGING_DONE=false
PRODUCTION_DONE=false
MAX_WAIT=1800
ELAPSED=0
CHECK_INTERVAL=15

while [ $ELAPSED -lt $MAX_WAIT ]; do
    # Check staging if not done
    if [ "$STAGING_DONE" = false ]; then
        STAGING_INFO=$(gh run view "$STAGING_RUN_ID" -R "$REPO" --json status,conclusion)
        STAGING_STATUS=$(echo "$STAGING_INFO" | jq -r '.status')
        STAGING_CONCLUSION=$(echo "$STAGING_INFO" | jq -r '.conclusion')
        
        if [ "$STAGING_STATUS" = "completed" ]; then
            STAGING_DONE=true
            if [ "$STAGING_CONCLUSION" = "success" ]; then
                echo -e "${GREEN}âœ“ STAGING deployment completed successfully${NC}"
                STAGING_SUCCESS=true
            else
                echo -e "${RED}âœ— STAGING deployment failed with conclusion: $STAGING_CONCLUSION${NC}"
                echo "Fetching first failing log line..."
                gh run view "$STAGING_RUN_ID" -R "$REPO" --log-failed 2>&1 | head -20
                exit 1
            fi
        fi
    fi
    
    # Check production if not done
    if [ "$PRODUCTION_DONE" = false ]; then
        PRODUCTION_INFO=$(gh run view "$PRODUCTION_RUN_ID" -R "$REPO" --json status,conclusion)
        PRODUCTION_STATUS=$(echo "$PRODUCTION_INFO" | jq -r '.status')
        PRODUCTION_CONCLUSION=$(echo "$PRODUCTION_INFO" | jq -r '.conclusion')
        
        if [ "$PRODUCTION_STATUS" = "completed" ]; then
            PRODUCTION_DONE=true
            if [ "$PRODUCTION_CONCLUSION" = "success" ]; then
                echo -e "${GREEN}âœ“ PRODUCTION deployment completed successfully${NC}"
                PRODUCTION_SUCCESS=true
            else
                echo -e "${RED}âœ— PRODUCTION deployment failed with conclusion: $PRODUCTION_CONCLUSION${NC}"
                echo "Fetching first failing log line..."
                gh run view "$PRODUCTION_RUN_ID" -R "$REPO" --log-failed 2>&1 | head -20
                exit 1
            fi
        fi
    fi
    
    # Exit if both are done
    if [ "$STAGING_DONE" = true ] && [ "$PRODUCTION_DONE" = true ]; then
        break
    fi
    
    # Show progress
    if [ "$STAGING_DONE" = false ] || [ "$PRODUCTION_DONE" = false ]; then
        if [ "$STAGING_DONE" = false ]; then
            echo "[STAGING] Status: $STAGING_STATUS | Elapsed: ${ELAPSED}s"
        fi
        if [ "$PRODUCTION_DONE" = false ]; then
            echo "[PRODUCTION] Status: $PRODUCTION_STATUS | Elapsed: ${ELAPSED}s"
        fi
    fi
    
    sleep $CHECK_INTERVAL
    ELAPSED=$((ELAPSED + CHECK_INTERVAL))
done

if [ $ELAPSED -ge $MAX_WAIT ]; then
    echo -e "${RED}âœ— Error: Workflow monitoring timed out${NC}"
    exit 1
fi

echo ""

# STEP 3: Extract URLs
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}STEP 3: Extracting deployment URLs${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Try to extract URLs from workflow logs first
echo "Checking workflow logs for deployment URLs..."

# For staging
STAGING_LOG=$(gh run view "$STAGING_RUN_ID" -R "$REPO" --log 2>&1 || echo "")
STAGING_URL_FROM_LOG=$(echo "$STAGING_LOG" | grep -oP 'https://[a-zA-Z0-9\-]+\.pages\.dev' | head -1 || echo "")

# For production
PRODUCTION_LOG=$(gh run view "$PRODUCTION_RUN_ID" -R "$REPO" --log 2>&1 || echo "")
PRODUCTION_URL_FROM_LOG=$(echo "$PRODUCTION_LOG" | grep -oP 'https://[a-zA-Z0-9\-]+\.pages\.dev' | head -1 || echo "")

# If not found in logs, use wrangler CLI
if [ -z "$STAGING_URL_FROM_LOG" ]; then
    echo "URL not found in staging logs, fetching via wrangler CLI..."
    
    # Check if wrangler is available
    if ! command -v wrangler &> /dev/null; then
        echo "Installing wrangler..."
        npm install -g wrangler
    fi
    
    # Get staging URL from wrangler
    STAGING_DEPLOYMENT_JSON=$(npx wrangler pages deployment list --project-name "$STAGING_PROJECT" --format json 2>/dev/null || echo "[]")
    STAGING_URL=$(echo "$STAGING_DEPLOYMENT_JSON" | jq -r '.[0].url // empty' || echo "")
    
    if [ -z "$STAGING_URL" ]; then
        echo -e "${YELLOW}âš  Warning: Could not fetch staging URL from wrangler${NC}"
        STAGING_URL="https://${STAGING_PROJECT}.pages.dev"
        echo "Using default URL: $STAGING_URL"
    fi
else
    STAGING_URL="$STAGING_URL_FROM_LOG"
fi

if [ -z "$PRODUCTION_URL_FROM_LOG" ]; then
    echo "URL not found in production logs, fetching via wrangler CLI..."
    
    # Get production URL from wrangler
    PRODUCTION_DEPLOYMENT_JSON=$(npx wrangler pages deployment list --project-name "$PRODUCTION_PROJECT" --format json 2>/dev/null || echo "[]")
    PRODUCTION_URL=$(echo "$PRODUCTION_DEPLOYMENT_JSON" | jq -r '.[0].url // empty' || echo "")
    
    if [ -z "$PRODUCTION_URL" ]; then
        echo -e "${YELLOW}âš  Warning: Could not fetch production URL from wrangler${NC}"
        PRODUCTION_URL="https://${PRODUCTION_PROJECT}.pages.dev"
        echo "Using default URL: $PRODUCTION_URL"
    fi
else
    PRODUCTION_URL="$PRODUCTION_URL_FROM_LOG"
fi

echo -e "${GREEN}âœ“ Staging URL: $STAGING_URL${NC}"
echo -e "${GREEN}âœ“ Production URL: $PRODUCTION_URL${NC}"
echo ""

# STEP 4: Smoke checks
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}STEP 4: Running smoke checks${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Function to run smoke check
smoke_check() {
    local url=$1
    local environment=$2
    
    echo -e "${YELLOW}Testing $environment...${NC}"
    
    # Test main page
    echo -n "  GET ${url}/ ... "
    HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -L --connect-timeout 10 --max-time 30 "$url/" 2>/dev/null || echo "000")
    
    if [ "$HTTP_CODE" = "200" ]; then
        echo -e "${GREEN}âœ“ PASS${NC} ($HTTP_CODE)"
    else
        echo -e "${RED}âœ— FAIL${NC} ($HTTP_CODE)"
        echo -e "${RED}Error: ${url}/ returned HTTP $HTTP_CODE${NC}"
        return 1
    fi
    
    # Try health endpoints (optional)
    for health_path in "/api/healthz" "/__health"; do
        echo -n "  GET ${url}${health_path} ... "
        HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -L --connect-timeout 10 --max-time 30 "${url}${health_path}" 2>/dev/null || echo "000")
        
        if [ "$HTTP_CODE" = "200" ]; then
            echo -e "${GREEN}âœ“ PASS${NC} ($HTTP_CODE)"
        elif [ "$HTTP_CODE" = "404" ]; then
            echo -e "${YELLOW}âŠ˜ SKIP${NC} (not implemented)"
        else
            echo -e "${YELLOW}âš  INFO${NC} ($HTTP_CODE)"
        fi
    done
    
    echo ""
    return 0
}

# Run smoke checks
if ! smoke_check "$STAGING_URL" "STAGING"; then
    echo -e "${RED}âœ— STAGING smoke check failed${NC}"
    exit 1
fi

if ! smoke_check "$PRODUCTION_URL" "PRODUCTION"; then
    echo -e "${RED}âœ— PRODUCTION smoke check failed${NC}"
    exit 1
fi

echo -e "${GREEN}âœ“ All smoke checks passed${NC}"
echo ""

# STEP 5: Final report
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}STEP 5: Final Report${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Display summary
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}âœ… DEPLOYMENT COMPLETE${NC}"
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""
echo "STAGING âœ…  $STAGING_URL"
echo "  â†’ Workflow: $STAGING_RUN_URL"
echo ""
echo "PRODUCTION âœ…  $PRODUCTION_URL"
echo "  â†’ Workflow: $PRODUCTION_RUN_URL"
echo ""
echo -e "${GREEN}âœ… Both deployments completed successfully${NC}"
echo -e "${GREEN}âœ… All smoke checks passed${NC}"
echo -e "${GREEN}âœ… No Vercel usage detected in pipeline${NC}"
echo ""

# Create comment body for posting to GitHub
COMMENT_BODY="# ðŸš€ Cloudflare Pages Deployment Complete

## STAGING âœ…
- **URL:** $STAGING_URL
- **Workflow Run:** $STAGING_RUN_URL
- **Status:** âœ… Deployed and verified

## PRODUCTION âœ…
- **URL:** $PRODUCTION_URL
- **Workflow Run:** $PRODUCTION_RUN_URL
- **Status:** âœ… Deployed and verified

---

**Deployment Status:** âœ… COMPLETE

Both staging and production deployments completed successfully with all smoke tests passing.
No Vercel usage detected in the pipeline."

# Save report to file
REPORT_FILE="/tmp/deployment-report.md"
echo "$COMMENT_BODY" > "$REPORT_FILE"
echo "Report saved to: $REPORT_FILE"
echo ""

# If running in PR context or issue number provided, post comment
if [ -n "$1" ]; then
    echo "Posting comment to issue/PR #$1..."
    gh issue comment "$1" -R "$REPO" -F "$REPORT_FILE"
    echo -e "${GREEN}âœ“ Comment posted${NC}"
elif [ -n "$GITHUB_REF" ] && [[ "$GITHUB_REF" == refs/pull/* ]]; then
    PR_NUMBER=$(echo "$GITHUB_REF" | sed 's|refs/pull/||' | sed 's|/merge||')
    echo "Posting comment to PR #$PR_NUMBER..."
    gh pr comment "$PR_NUMBER" -R "$REPO" -F "$REPORT_FILE"
    echo -e "${GREEN}âœ“ Comment posted${NC}"
fi

echo ""
echo -e "${GREEN}âœ… All operations completed successfully!${NC}"
